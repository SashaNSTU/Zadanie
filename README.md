## Этот проект позволяет извлечь данные о строениях с улиц Новосибирска и сохранить их в базе данных PostgreSQL. Процесс выполнения состоит из следующих шагов:

1. Установка зависимостей
2. Поднятие базы данных с помощью docker-compose
3. Запуск скрипта для сбора данных
4. Результаты сохраняются в базе данных

Прежде чем начать сбор данных, вам нужно поднять сервер с БД и настроить файл `config.py` соответствующим образом. Пример настроек в файле:

1. host = "localhost"
2. port = "5432"
3. user = "admin"
4. password = "root"
5. db_name = "TestZadanie"

Парсил сайт https://dom.mingkh.ru/, приходилось сначала получать названия каждой улицы, а потом парсить каждую улицу на наличие разных жилых домов с их координатами. Скорее всего есть сайт, который отдаст за один запрос все дома с их координатами, но я не нашел.
Пытался ускорить процесс с помощью многопоточки. При 10 потоках, программа парсит за 40 секунд 7845 домов из 8590 доступных на сайте (на сайте есть дома без года постройки, но не думаю что их около 700 все-таки). Если увеличивать число поток скорость выполнения пропорционально увеличивается, но уменьшается кол-во
домов. Какая-то проблема с разграничиванием потоков, т.к. особо не шарю в них, не смог разобраться.

К локальной БД не получилось подключиться через datalens, поэтому сначала скачал просто .csv файл, чтобы вообще попробовать что такое Yandex Datalens. Впервые пользовался данным сервисом поэтому не знаю как даже оценивать, то что я сделал, и то ли я вообще сделал, что требовалось.
![image](https://github.com/SashaNSTU/Zadanie/assets/96714711/c61ccdb0-0c0d-45ef-a33c-3caeaf26b757)
https://datalens.yandex/5eie342n66e0u

Потом поднял на vds сервере БД, всё там сработало, но не за 40 секунд конечно. Сервер подключил, создал чарт, но не стал доделывать, потому что попросили пораньше скинуть работу. Получилось бы то же самое, что и с файлом .csv выше.
![image](https://github.com/SashaNSTU/Zadanie/assets/96714711/2f2e349b-b1a5-4ee2-8300-3d23eed49117)
https://datalens.yandex/dmv8wek7ann82
